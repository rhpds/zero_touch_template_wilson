= Advanced Lab Features and Special Cases

== Learning Outcomes

Upon completion, you will understand:

* Advanced platform feature configuration including backend SSH access and complex networking
* Business Unit-specific requirements for RHEL, Ansible, and other teams  
* Specialized workloads and extensions for enterprise applications
* Complex security patterns and certificate management
* Advanced deployment scenario troubleshooting and integration issues

== Overview

Beyond basic template customization, some labs require specialized configurations for:

* **Business Unit Requirements**: Specific features needed by RHEL, Ansible, and other teams
* **Advanced Networking**: Complex routing and certificate handling
* **Specialized Workloads**: Satellite, bootc images, and enterprise applications
* **Integration Requirements**: Satellite registration, pull secrets, and authentication

== Platform Architecture

[TIP]
====
**Quick Reference**: Zero Touch uses Git repository → AgnosticD deployment → OpenShift CNV → Showroom UI → Wetty terminals
**Key insight**: Content builds statically but runtime validation is dynamic via automation scripts
====

=== Core Components

* **AgnosticD**: Deployment engine that provisions infrastructure
* **Showroom**: Web interface framework for lab navigation  
* **zerotouch-automation/cli**: Runs setup and automation scripts
* **zerotouch-automation/api**: Handles runtime module execution
* **nookbag**: Lab interface with progress tracking and navigation
* **caddy**: Reverse proxy and static file server
* **wetty**: Web-based terminal access

== Advanced Instance Features

[TIP]
====
**Quick Reference**: SSH root access, bootloader configs, isolation patterns, complex networking
**When to use**: Enterprise VMs, specialized images, multi-platform labs
====

=== Backend Configuration

==== SSH Root Login

Enable SSH root access for wetty terminal integration:

[source,yaml]
----
virtualmachines:
  - name: "control-node"
    image: "rhel-9.6"
    memory: "4G"
    cores: 2
    image_size: "40G"
    userdata: |
      #cloud-config
      users:
        - name: root
          ssh_authorized_keys:
            - ssh-rsa AAAAB3... # Lab SSH key
      runcmd:
        - echo "PermitRootLogin yes" >> /etc/ssh/sshd_config
        - systemctl restart sshd
    networks:
      - default
----

==== VirtIO Networking

Default interface configuration for consistent naming:

[source,yaml]
----
virtualmachines:
  - name: "rhel-server"
    image: "rhel-9.6"
    memory: "4G"
    cores: 2
    image_size: "40G"
    # VirtIO is default - interface will be enp1s0
    networks:
      - default
----

=== Special Lab Scenarios

==== Bootc Image Mode Labs

For labs converting VMs to image mode (bootc), special handling is required:

[source,yaml]
----
# In setup-automation/main.yml
- name: Fetch private SSH key before bootc conversion
  ansible.builtin.slurp:
    src: "/home/rhel/.ssh/{{ guid }}key.pem"
  register: r_slurp

- name: Save SSH key for later use
  ansible.builtin.copy:
    dest: "/tmp/{{ guid }}key.pem"
    content: "{{ r_slurp['content'] | b64decode }}"
    mode: 0600
  delegate_to: localhost

- name: Preserve /etc/hosts configuration
  ansible.builtin.slurp:
    src: "/etc/hosts"
  register: r_etc_hosts

# After bootc conversion, recreate users and configuration
- name: Recreate rhel user after bootc conversion
  ansible.builtin.user:
    name: rhel
    password: "{{ rhel_user_password | password_hash('sha512') }}"
    state: present
    shell: /bin/bash
    create_home: yes
    home: /home/rhel
    groups: wheel
    append: yes

- name: Enable root SSH access
  ansible.builtin.copy:
    content: |
      PermitRootLogin yes
    dest: /etc/ssh/sshd_config.d/ansible_permit_root_login.conf
    owner: root
    group: root
    mode: '0644'

- name: Restore /etc/hosts
  ansible.builtin.copy:
    src: /tmp/hosts
    dest: /etc/hosts
----

==== Satellite Registration for Ansible Labs

Ansible Business Unit images require Satellite registration:

[source,yaml]
----
# In setup-automation/main.yml
vars:
  satellite_url: "{{ lookup('ansible.builtin.env', 'SATELLITE_URL') }}"
  satellite_org: "{{ lookup('ansible.builtin.env', 'SATELLITE_ORG') }}"
  satellite_activationkey: "{{ lookup('ansible.builtin.env', 'SATELLITE_ACTIVATIONKEY') }}"

tasks:
  - name: Execute setup script with Satellite variables
    shell: "sh -x /tmp/setup-scripts/setup-{{ ansible_host }}.sh > /tmp/setup-scripts/setup-{{ ansible_host }}.log 2>&1"
    become: true
    register: r_result
    environment:
      SATELLITE_URL: "{{ satellite_url }}"
      SATELLITE_ORG: "{{ satellite_org }}"
      SATELLITE_ACTIVATIONKEY: "{{ satellite_activationkey }}"
----

==== Registry Pull Secrets

For accessing Red Hat registry images:

[source,yaml]
----
# In setup-automation/main.yml
- name: Execute setup with registry credentials
  shell: "sh -x /tmp/setup-scripts/setup-{{ ansible_host }}.sh > /tmp/setup-scripts/setup-{{ ansible_host }}.log 2>&1"
  become: true
  register: r_result
  environment:
    REGISTRY_PULL_TOKEN: "{{ lookup('ansible.builtin.env', 'REGISTRY_PULL_TOKEN') }}"
    GUID: "{{ lookup('ansible.builtin.env', 'GUID') }}"
    DOMAIN: "{{ lookup('ansible.builtin.env', 'DOMAIN') }}"
----

== Advanced Networking Features

=== Reencrypt Routes

For services with self-signed certificates, use reencrypt termination:

[source,yaml]
----
# In instances.yaml
virtualmachines:
  - name: "control-server"
    image: "rhel-9.6"
    memory: "4G"
    cores: 2
    image_size: "40G"
    networks:
      - default
    services:
      - name: control-https
        ports:
          - port: 443
            protocol: TCP
            targetPort: 443
            name: https
    routes:
      - name: control-https
        host: control
        service: control-https
        targetPort: 443
        tls: true
        tls_termination: reencrypt
        tls_destinationCACertificate: |
          -----BEGIN CERTIFICATE-----
          # Replace with your actual certificate
          # This is a placeholder for documentation purposes
          # Generate your certificate using:
          # openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 365 -nodes
          -----END CERTIFICATE-----
----

=== DNS and FQDN Configuration

Configure proper hostnames and DNS resolution:

[source,yaml]
----
virtualmachines:
  - name: "satellite"
    image: "satellite-server-latest"
    memory: "8G"
    cores: 4
    image_size: "100G"
    userdata: |
      #cloud-config
      fqdn: satellite.lab
      hostname: satellite
      prefer_fqdn_over_hostname: true
      manage_etc_hosts: true
    networks:
      - default
----

Testing DNS resolution:
[source,bash]
----
[rhel@control ~]$ ping node01.lab
PING node01.lab.sandbox-kvwkp-ocp4-cluster.svc.cluster.local (10.131.8.249) 56(84) bytes of data.
64 bytes from 10-131-8-249.node01-http.sandbox-kvwkp-ocp4-cluster.svc.cluster.local (10.131.8.249): icmp_seq=1 ttl=62 time=3.33 ms
----

=== Iframe Support

Remove X-Frame-Options headers for embedded applications:

[source,yaml]
----
# In routes configuration
routes:
  - name: satellite-web
    host: satellite
    service: satellite-web
    targetPort: 443
    tls: true
    tls_termination: reencrypt
    httpHeaders:
      actions:
        response:
          - name: X-Frame-Options
            action:
              type: Delete
----

== Advanced Container Features

=== Container Initialization Commands

Execute commands after container startup:

[source,yaml]
----
containers:
  - name: gitea
    image: quay.io/agonzalezrh/gitea:1.16.8-rootless
    ports:
      - name: gitea
        containerPort: 3000
        protocol: TCP
    environment:
      GITEA__DEFAULT__RUN_MODE: dev
      GITEA__database__DB_TYPE: sqlite3
      GITEA__security__INSTALL_LOCK: "true"
    commands:
      - gitea admin user create --admin --username gitea --password gitea --email dummy@dummy.com --must-change-password=false
      - |
        curl -X POST -H "accept: application/json" -H "Content-Type: application/json" \
             -u 'gitea:gitea' \
             -d '{"username": "student", "full_name": "student", "description": "student"}' \
             http://localhost:3000/api/v1/orgs
    volumes:
      - name: gitea-data
        emptyDir: {}
    memory: "2G"
----

=== Complex Container Configurations

Example Kafka broker with full configuration:

[source,yaml]
----
containers:
  - name: broker                        # Example Kafka broker
    image: confluentinc/cp-kafka:7.0.1
    ports:
      - name: broker
        containerPort: 9092
        protocol: TCP
    environment:
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_BROKER_ID: "1"
    volumeMounts:
      - name: kafka-varlog
        mountPath: /var/log/kafka/
    volumes:
      - name: kafka-varlog
        emptyDir: {}
    memory: "4G"
----

== Troubleshooting Common Issues

=== Instance Configuration Problems

==== Boot Loader Issues

**Problem**: VM fails to boot with EFI-configured images
**Solution**: Ensure `bootloader: efi` is set for Business Unit provided images

==== Disk Type Compatibility

**Problem**: Windows or Ansible BU images fail with VirtIO disks
**Solution**: Use `disk_type: "scsi"` for compatibility

==== Network Interface Naming

**Problem**: Scripts expect specific interface names
**Solution**: Use VirtIO (default) for `enp1s0` or configure cloud-init networking

=== Container Issues

==== Registry Access

**Problem**: Cannot pull images from registry.redhat.io
**Solution**: Ensure `REGISTRY_PULL_TOKEN` environment variable is set

==== Command Execution

**Problem**: Container initialization commands fail
**Solution**: Check command syntax and ensure dependencies are available

=== Networking Problems

==== Certificate Issues

**Problem**: Self-signed certificate warnings
**Solution**: Use `tls_termination: reencrypt` with proper CA certificate

==== DNS Resolution

**Problem**: Services cannot resolve `.lab` hostnames
**Solution**: Configure DNS search domains and verify cloud-init FQDN settings

==== Iframe Blocking

**Problem**: Web applications cannot be embedded
**Solution**: Remove `X-Frame-Options` header using route configuration

=== Authentication and Access

==== SSH Access Issues

**Problem**: Cannot SSH to instances as root
**Solution**: Configure SSH root login and password authentication

==== Satellite Registration

**Problem**: Cannot install packages on Ansible BU instances
**Solution**: Configure Satellite registration variables in setup automation

== Best Practices

=== Security

* Use strong passwords in cloud-init configurations
* Limit SSH access to necessary users
* Configure proper certificate handling for HTTPS services
* Use isolated node configuration for pre-built images

=== Performance

* Allocate appropriate resources based on workload requirements
* Use VirtIO for networking unless compatibility requires SCSI
* Configure proper memory limits for containers
* Monitor resource usage during lab execution

=== Maintenance

* Document special configurations and their purposes
* Test lab scenarios thoroughly before deployment
* Keep track of Business Unit specific requirements
* Version control all configuration changes

=== Development Workflow

* Start with basic configurations and add complexity incrementally
* Test each component independently before integration
* Use descriptive names for instances, networks, and services
* Follow naming conventions for consistency

== AgnosticD Workload Extensions

[TIP]
====
**Quick Reference**: 200+ pre-built workloads for development, CI/CD, security, registries
**Alternative to**: Custom container configurations in `instances.yaml`
**Benefits**: Standardized, maintained, enterprise-ready deployments
====

=== Available Extension Workloads

Zero Touch deployments support **200+ specialized workloads** for advanced lab requirements:

** Development Tools**:
- `ocp4_workload_codeserver` - Browser-based VS Code IDE with Git integration
- `ocp4_workload_devspaces` - Eclipse Che development environments  
- `ocp4_workload_gitea_operator` - Self-hosted Git repository platform

** CI/CD & Automation**:
- `ocp4_workload_jenkins` - Jenkins CI/CD pipelines
- `ocp4_workload_pipelines` - Tekton OpenShift Pipelines
- `ocp4_workload_gitops_bootstrap` - ArgoCD GitOps workflows

** Container & Registry Management**:
- `ocp4_workload_quay_operator` - Private container registries
- `ocp4_workload_nexus_operator` - Artifact repository management
- `ocp4_workload_openshift_container_storage` - Persistent storage

**🔐 Security & Compliance**:
- `ocp4_workload_rhacs` - Red Hat Advanced Cluster Security
- `ocp4_workload_cert_manager` - Automated certificate management
- `ocp4_workload_vault` - HashiCorp Vault secret management

=== Configuring Workloads

**In AgnosticV `common.yaml`:**
[source,yaml]
----
# Extension workloads by deployment phase
pre_software_workloads:
  bastions:
    - gitea_operator

software_workloads:
  localhost:
    - codeserver
    - jenkins

post_software_workloads:
  bastions:
    - rhacs
    - quay_operator
----

**Workload Target Options**:
- `localhost` - Control node tasks
- `bastions` - Bastion/jump servers
- `nodes` - Worker nodes
- `all` - All managed hosts
- `windows` - Windows systems
- `satellites` - Satellite servers

=== Custom Workload Development

**Create Custom Extensions**:
[source,text]
----
roles_ocp_workloads/
├── ocp4_workload_my_custom_app/
│   ├── defaults/main.yml          # Default variables
│   ├── tasks/workload.yml         # Main deployment logic
│   ├── tasks/pre_workload.yml     # Pre-deployment setup
│   ├── tasks/post_workload.yml    # Post-deployment tasks
│   └── templates/                 # Jinja2 templates
----

**Integration Benefits**:
- Standardized deployment patterns
- Automatic error handling and retries
- Integration with Zero Touch security model  
- Shared variable access (`guid`, `common_password`, etc.)
- Built-in validation and testing hooks

== Related Documentation

* xref:vm-basics.adoc[Adding Instances and Containers]
* xref:networking-basics.adoc[Configuring Networking]
* xref:firewall-basics.adoc[Configuring Firewall Rules]
* xref:content-authoring-basics.adoc[Creating Lab Content and UI Configuration]
* xref:template-customization-guide.adoc[Template Customization Guide]

[bibliography]
== References

* [[[roadshow-instances]]] Red Hat Ansible Team. AAP 2.5 Roadshow Lab Instance Configuration. 
  AgnosticV Git Repository - zt-ans-bu-roadshow01/config/instances.yaml. 2024.

* [[[template-instances]]] Red Hat GPTE Team. Zero Touch Template Instance Configuration. 
  `https://github.com/rhpds/lab_zero_touch_template.git` - config/instances.yaml. 2024.

* [[[agnosticd-base]]] Red Hat GPTE Team. AgnosticD Zero Touch Base RHEL Configuration. 
  AgnosticD Git Repository - ansible/configs/zero-touch-base-rhel/default_vars_openshift_cnv.yaml. 2024.

== External Resources

* https://github.com/rhpds/zerotouch-automation[Zero Touch Automation Repository]
* https://github.com/rhpds/nookbag/[Nookbag Lab Interface]
* https://docs.antora.org/[Antora Documentation Generator]
* https://cloud-init.io/[Cloud-Init Documentation]
